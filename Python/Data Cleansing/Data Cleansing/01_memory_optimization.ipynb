{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizando el uso de memoria\n",
    "Cuando trabajamos con `pandas`, normalmente nuestro equipo no experimentará problemas de rendimiento mientras los datos que manejemos tengan un tamaño por debajo de los 100 megabytes. A partir de aquí los tiempos de ejecución se incrementan y nos exponemos a errores de **memoria insuficiente**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver cómo optimizar el uso de la memoria poniendo a la hora de cargar nuestros datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/baseball.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando datos\n",
    "Para ilustrar el caso manejaremos un fichero de datos procedente de [Retrosheet](http://www.retrosheet.org/gamelogs/index.html), priméramente cargaremos dicho fichero y veremos que aspecto tiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = pd.read_csv('datasets/MLB/mlb_games.csv', low_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.read_csv` proporciona multitud de parámetros, entre ellos `low_memory` que admite dos valores posibles,\n",
    "* `True`, (valor por defecto) a la hora de cargar el fichero, en vez de procesarlo entero, lo hace por trozos. Esto implica un uso más óptimo de memoria en tiempo de carga (aunque también la posibilidad de \"mixed types\")\n",
    "* `False`, determina el valor del tipo de dato una vez ha leído todas y cada una de las líneas del fichero evitando de esta manera conflictos de \"mixed types\" a costa de un mayor consumo de memoria en tiempo de carga.\n",
    "\n",
    "Para más información se puede consultar https://github.com/pandas-dev/pandas/pull/13293#pullrequestreview-8216118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisamos el aspecto de nuestros datos, segúramente no comprendamos el significado de los campos. Para lo que se trata de ilustrar tampoco importa demasiado, no obstante se incluye un enlace al [diccionario de campos](http://www.retrosheet.org/gamelogs/glfields.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible ajustar el display de nuestro notebook mediante una serie de opciones,\n",
    "* pd.set_option('display.height', <value>)\n",
    "* pd.set_option('display.max_rows', <value>)\n",
    "* pd.set_option('display.max_columns', <value>)\n",
    "* pd.set_option('display.width', <value>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora queremos ver el consumo de memoria que la carga de datos ha conllevado. Por defecto `pandas` nos da una aproximación, pero esta vez vamos a \"forzar\" para que nos dé una estimación más precisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mg.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Vaya! son unos cuantos megas...vemos como `pandas` ha operado de la siguiente manera\n",
    "* Para cualquier número entero utiliza el tipo `int64`.\n",
    "* Para cualquier número en coma flotante utiliza el tipo `float64`.\n",
    "* Para cualquier string, o cualquier campo cuyos valores presenten mezcla de tipos, utilizará el tipo `object`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En sus [tripas](https://github.com/pandas-dev/pandas/blob/master/pandas/core/internals/blocks.py), `pandas` utiliza la clase `ObjectBlock` para representar aquellas columnas formadas por strings y tipos mixtos, la clase `IntBlock` para representar las formadas por enteros y para las columnas que contienen números en coma flotante, la clase `FloatBlock`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero lo que es más interesante, es que para todo lo que son números (sean enteros ó en coma flotante), `pandas` almacena sus valores como arrays de `numpy` (que como sabemos se basan en arrays de C) de tal manera que sus valores se almacenan en bloques contiguos de memoria. En pocas palabras, el acceso a este tipo de datos en `pandas` es muy ágil gracias a que se apoya en los `ndarray` de `numpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero...¿qué tienen los `ndarray` para que sean eficientes?\n",
    "* Los tipos de datos de las entradas del array.\n",
    "* Un puntero a un bloque contiguo de memoria donde residen los datos del array.\n",
    "* Una tupla que contenga la dimensión (shape) del array.\n",
    "* Una tupla que contenga el stride (el tamaño del salto que hay que dar para moverse de un elemento a otro del array en las diferentes dimensiones del mismo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que cada tipo de dato se almacena por separado en memoria, revisaremos el consumo medio por tipo de columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dtype in ['float','integer','object']:\n",
    "    selected_dtype = mg.select_dtypes(include=[dtype])\n",
    "    mean_usage_bytes = selected_dtype.memory_usage(deep=True)[1:].mean()\n",
    "    mean_usage_mbytes = mean_usage_bytes / (1024**2)\n",
    "    print(\"Uso medio de memoria para una columna de tipo {}: {:03.2f} MB\".format(dtype,mean_usage_mbytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pues sí...parece que lo menos óptimo de almacenar son los campos de tipo `object`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desgranando los tipos numéricos\n",
    "Ya comentamos antes que `pandas` (entre bambalinas) almacena los tipos numéricos como `ndarrays` de `numpy` en bloques contiguos de memoria lo cual permite optimizar el acceso y el espacio requerido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, hay que tener claro que principalmente los tipos numéricos (tanto `int` como `float`) vienen acompañados de sus propios subtipos que permiten ajustar mejor el número de bytes que se utilizará internamente para representar cada valor.\n",
    "* Por ejemplo el tipo float comprende a su vez los subtipos `float16`, `float32` y `float64`, esto quiere decir que cada valor de cada uno de esos tipos ocupará 16 bits (2 bytes), 32 bits (4 bytes) y 64 bits (8 bytes) respectívamente.\n",
    "* Para el tipo int, tendremos los subtipos `int8`, `int16`, `int32` e `int64`, con lo que cada valor representado por cada uno de ellos ocuparán 8 bits (1 byte), 16 bits (2 bytes), 32 bits (4 bytes) y 64 bits (8 bytes) respectívamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tipo `uint` (unsigned integer) también tiene sus propios subtipos de manera similar al int: `uint8`, `uint16`, `uint32` y `uint64`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero de poco nos sirve esto si no tenemos claro los mínimos y máximos valores que son capaces de representar; esta información nos la pone al alcance los siguientes métodos\n",
    "* Para números enteros `iinfo()`\n",
    "* Para números en coma flotante `finfo()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_types = [\"float64\"]\n",
    "for st in sub_types:\n",
    "    print(np.finfo(st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora muestra tú los límites para el subtipo que prefieras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizando los campos numéricos\n",
    "Utilizaremos el método `to_numeric()` de `pandas` para hacer un downgrade de los tipos numéricos al subtipo más pequeño posible. Vamos a crear una función para calcular y luego poder comparar el uso de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        usage_bytes = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else: # asumimos que si no es un DataFrame es una serie temporal (pandas Series)\n",
    "        usage_bytes = pandas_obj.memory_usage(deep=True)\n",
    "        \n",
    "    usage_mbytes = usage_bytes / 1024 ** 2 # para convertir de bytes a megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si echamos un vistazo a las columnas interpretadas como `integer` vemos que se trata de `date`, `number_of_game`, `v_game_number`, `h_game_number`, `v_score` y `h_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mg.select_dtypes(include=['integer']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En definitiva campos para los cuales un entero negativo no tendría sentido, es por ello que vamos a intentar hacer un downcast de los mismos a algún tipo de `unsigned`. Para ello utilizaremos la functión de `pandas`, `to_numeric`. Esta función hará lo siguiente,\n",
    "* Convertir el argumento que le pasemos a tipo numérico.\n",
    "* Si le pasamos algún valor al parámetro `downcast`, se intentará la conversión al subtipo más óptimo del tipo facilitado (ojo, esto solo ocurrirá si el parámetro ha podido ser convertido con éxito a tipo numérico o si ya era numérico).\n",
    "* Solo se realizará la conversión indicada por el parámetro `downcast`, si el tipo resultante es de menor tamaño que el original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mg_integer = mg.select_dtypes(include=['integer'])\n",
    "converted_uint = mg_integer.apply(pd.to_numeric,downcast='unsigned')\n",
    "\n",
    "print(\"Before \" + mem_usage(mg_integer))\n",
    "print(\"After \" + mem_usage(converted_uint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la mejora ha sido importante, aproximadamente un 80% de reducción del tamaño (aunque no es tan palpable en términos globales debido a las pocas features `integer` que tiene el dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat nos permite concatenar dos objetos de pandas,\n",
    "# a lo largo de un determinado eje que especificaremos con el\n",
    "# parámetro axis.\n",
    "compare_ints = pd.concat([mg_integer.dtypes,converted_uint.dtypes],axis=1)\n",
    "compare_ints.columns = ['before','after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_ints.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Repitamos la operación con nuestros tipos float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_float = mg.select_dtypes(include=['float'])\n",
    "converted_float = mg_float.apply(pd.to_numeric,downcast='float')\n",
    "\n",
    "print(\"Before \" + mem_usage(mg_float))\n",
    "print(\"After \" + mem_usage(converted_float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_floats = pd.concat([mg_float.dtypes, converted_float.dtypes], axis=1)\n",
    "compare_floats.columns = ['before', 'after']\n",
    "compare_floats.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que, mediante `pd.to_numeric()` y su parámetro `downcast`, se ha conseguido que los datos se ajusten a un tipo `float32`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ahora tenemos en `converted_int` y en `converted_float` las features (ó columnas) que hemos optimizado. Podemos crear una copia del DataFrame original y reemplazar sus columnas sin optimizar, por las que hemos optimizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_mg = mg.copy()\n",
    "\n",
    "optimized_mg[converted_uint.columns] = converted_uint\n",
    "optimized_mg[converted_float.columns] = converted_float\n",
    "\n",
    "print(\"Tamaño original del dataset: \" + mem_usage(mg))\n",
    "print(\"Tamaño optimizado del dataset (tocando solo integer y float): \" + mem_usage(optimized_mg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No está mal, pero parece que la mayor optimización vendrá de encargarnos de aquellas features almacenadas como tipo `object`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desgranando los objetos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veíamos como para los tipos numéricos, `pandas` se apoya en arrays de `numpy` (`ndarrays`) para optimizar su almacenamiento y por tanto el acceso a los mismos. Cuando hablamos de otros tipos como pueden ser los tipos `string`, numpy NO ofrece soporte para valores missing de esas características. Veamos esto con el comportamiento de la función de `numpy`, `isnan`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([2.0, 3, -10])\n",
    "np.isnan(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = np.array([2.0, 3, -10, 'hola'])\n",
    "np.isnan(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vemos como se almacenan los tipos numéricos (que se apoyan en los arrays de numpy) en comparación con los tipos string. (gráfico procedente de este [post](https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/storage.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que,\n",
    "* En el caso de los tipos numéricos se trata de un único puntero a un buffer en el que están de forma contigua almacenados los valores.\n",
    "* En el otro caso tenemos un puntero que a su vez apunta a buffer de punteros cada cual, a su vez, apunta al correspondiente objeto de Python que tiene la referencia al dato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿No hay manera de optimizar esto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la versión 0.15, `pandas` introdujo los llamados categoricals (el nombre concreto del tipo es `category`) que nos permite,\n",
    "* A partir de una feature ó columna que tenga un *número limitado de valores*.\n",
    "* `pandas` crea por debajo un diccionario en el que cada valor de esa feature se mapeara con un número entero.\n",
    "* Para ello utiliza el subtipo entero más eficiente posible capaz de representar todos los valores de esa feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/category.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Parece buena idea pero...¿qué se quiere decir exactamente con un número *limitado* de valores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_object = mg.select_dtypes(include=['object']).copy()\n",
    "mg_object.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta que nuestro dataset consta de unos 170000 registros, el número de valores únicos a simple vista es comparativamente bajo. Vamos a ver que pasaría si aplicamos un tipo `category` a, por ejemplo, `day_of_week`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow = mg.day_of_week\n",
    "print(dow.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora haremos un casting o conversión de esta columna para que sea de tipo `category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_cat = dow.astype('category')\n",
    "print(dow_cat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los códigos que \"por debajo\" han sido asociados a cada categoría del tipo `category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(enumerate(dow_cat.cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_cat.head().cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro caso la feature `day_of_week` no tiene ningún valor missing, pero si así fuera el tipo `category` lo gestionaría asignándole el valor -1. Vamos a ver la ganancia de memoria que hayamos podido obtener tras la conversión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mem_usage(dow))\n",
    "print(mem_usage(dow_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bastante impresionante, aunque\n",
    "* Hay que tener en cuenta que este es un caso especialmente bueno (7 valores únicos y más de 170000 registros)\n",
    "* Se pierde la posibilidad de hacer cálculos aritméticos y utilizar ciertos métodos como `min()` y `max()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una cuestión que seguro rondará la cabeza es...¿cuándo es realmente interesante recurrir a los tipos `category`? bueno, lo suyo es hacerlo cuando el número de valores únicos de una feature sea menor que el 50% del total...de lo contrario podríamos incurrir en un uso incluso mayor de memoria que si no usáramos los tipos `category`. Para saber más del tipo `category`, la documentación es de [ayuda](http://pandas.pydata.org/pandas-docs/stable/categorical.html#gotchas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a esta regla que hemos establecido, comprobaremos para cada feature de tipo object si menos del 50% de sus valores son únicos y para las que cumplan la condición, se realizará la conversión a `category`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mg_object.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_obj = pd.DataFrame()\n",
    "\n",
    "for col in mg_object:\n",
    "    num_unique_values = len(mg_object[col].unique())\n",
    "    num_total_values = len(mg_object[col])\n",
    "    \n",
    "    if (num_unique_values / num_total_values) < 0.5:\n",
    "        converted_obj[col] = mg_object[col].astype('category')\n",
    "    else:\n",
    "        converted_obj[col] = mg_object[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mem_usage(mg_object))\n",
    "print(mem_usage(converted_obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_obj = pd.concat([mg_object.dtypes, converted_obj.dtypes], axis=1)\n",
    "compare_obj.columns = ['before','after']\n",
    "compare_obj.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mg_object.v_league.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_object.h_league.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es momento de recopilar las mejores realizadas en los tipos numéricos y ver cual ha sido la optimización global con respecto a nuestra situación inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_mg[converted_obj.columns] = converted_obj\n",
    "mem_usage(optimized_mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos pasado de 860.5 MB a 103.63 MB.\n",
    "Pero antes de cerrar, recordemos que la primera columna de nuestro dataset era la feature `date` que a la hora de ejecutar el método `read_csv` al principio, fue considerada como `integer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = optimized_mg.date\n",
    "print(mem_usage(date))\n",
    "date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta conversión no tiene mucho sentido y, aunque en términos de memoria nos salga más caro, lo coherente y útil a la hora de analizar nuestros datos será convertirlo a tipo `datetime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimized_mg['date'] = pd.to_datetime(date,format='%Y%m%d')\n",
    "print(mem_usage(optimized_mg))\n",
    "optimized_mg.date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Existe la posibilidad de seleccionar los tipos antes de crear el DataFrame?\n",
    "Por suerte sí, ya que el método `pandas.read_csv` (`pd.read_csv` en nuestro caso, por el alias `pd` utilizado para referinos a `pandas`) tiene varios parámetros que nos permitirá informar a `pandas` del tipo de nuestras features.\n",
    "Cabe destacar el parámetro `dtype` el cual es un diccionario cuyas claves son los nombres de las features y sus valores son tipos de `numpy`. Veamos en que consiste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puede parecer raro que prescindamos de la feature date,\n",
    "# es simplemente para ver como pandas la gestionar por nosotros\n",
    "optimized_types = optimized_mg.drop('date', axis=1).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_types_col = optimized_types.index\n",
    "optimized_types_type = [i.name for i in optimized_types.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos por un lado dos listas, una con el nombre de las features y otra con su tipo óptimo. Preparamos el diccionario con ambas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dtypes = dict(zip(optimized_types_col, optimized_types_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora cargaremos de nuevo el dataset con nuestro diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_optimized = pd.read_csv('datasets/MLB/mlb_games.csv', dtype=column_dtypes, parse_dates=['date'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mem_usage(read_optimized))\n",
    "read_optimized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible que para un dataset de este tamaño no parezca tan necesario el investigar sobre la tipología de nuestras features. Pero, como hemos visto, dejar que `pandas` infiera los tipos implica un mayor tiempo de carga (ya que hasta que no lea todo el fichero no determinará el tipo de una feature) y además, para evitar problemas, siempre tirará por aquellos subtipos con mayor precisión (64 bits)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Un uso más efectivo de `pandas` supondrá una mayor eficiencia en nuestras tareas cuando manejemos datasets de cierto tamaño."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
